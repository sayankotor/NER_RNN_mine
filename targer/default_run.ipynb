{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_test.csv: 112 samples, 644 words.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 97, in <module>\n",
      "    datasets_bank.add_train_sequences(word_sequences_train, tag_sequences_train)\n",
      "  File \"/home/vika/NER_RNN/targer/src/classes/datasets_bank.py\", line 26, in add_train_sequences\n",
      "    self.__add_to_unique_words_list(word_sequences_train)\n",
      "  File \"/home/vika/NER_RNN/targer/src/classes/datasets_bank.py\", line 17, in __add_to_unique_words_list\n",
      "    if word not in self.unique_words_list:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/NER_RNN/targer\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## birnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiRNNCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv: 523 samples, 14728 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv: 523 samples, 14728 words.\n",
      "word_sequences_dev 523 [['and', 'can', 'i', 'just', 'say', 'that', 'doing', 'the', 'inferno', 'move', 'on', 'the', 'ds', 'is', '50', 'times', 'easier', 'than', 'trying', 'to', 'make', 'an', 'infinity', 'symbol', 'using', 'the', 'wii', 'remote', '.'], ['i', 'go', 'to', 'the', 'amazon', 'mp3', 'store', '(', 'better', 'than', 'itunes', '.'], ['tea', 'dinner', '(', 'sorry', '\"', 'my', 'wife', 'is', 'trying', 'to', 'make', 'me', 'posherer', ')', 'and', 'picking', 'up', 'a', 'phone', 'is', 'easier', '-', 'then', 'i', 'can', 'swig', 'my', 'beer', 'and', 'relaaaaxxxx', '...', '.', '.'], ['actually', 'for', 'many', 'windows', 'xp', 'users', 'it', 'is', 'easier', 'to', 'migrate', 'to', 'linux', 'mint', 'than', 'to', 'windows', '8', '.'], ['this', 'is', 'why', 'the', 'better', 'team', 'wins', 'any', 'given', 'basketball', 'game', 'with', 'far', 'greater', 'frequency', 'than', 'it', 'does', 'in', 'baseball', '\"', 'football', 'or', 'hockey', '.']]\n",
      "tag_sequences_train 523 [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O'], ['B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-ASPOBJ', 'I-ASPOBJ', 'O', 'O', 'O', 'B-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'I-ASP', 'O', 'O', 'B-OTHOBJ', 'I-OTHOBJ', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPOBJ', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OTHOBJ', 'O', 'O', 'O', 'O', 'O']]\n",
      "DatasetsBank: len(unique_words_list) = 7143 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7753 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7753 unique words.\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 0\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 25000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 50000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 75000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 100000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 125000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 150000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 175000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 200000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 225000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 250000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 275000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 300000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 325000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 350000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 375000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 0\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 25000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 50000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 75000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 100000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 125000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 150000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 175000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 200000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 225000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 250000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 275000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 300000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 325000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 350000\n",
      "Reading embeddings file embeddings/glove.6B.100d.txt, line = 375000\n",
      "\n",
      "load_vocabulary_from_embeddings_file_and_unique_words_list:\n",
      "    First 50 OOV words:\n",
      "        out_of_vocabulary_words_list[0] = b'1tb'\n",
      "        out_of_vocabulary_words_list[1] = b'hgst'\n",
      "        out_of_vocabulary_words_list[2] = b''\n",
      "        out_of_vocabulary_words_list[3] = b'256kbps'\n",
      "        out_of_vocabulary_words_list[4] = b'..and'\n",
      "        out_of_vocabulary_words_list[5] = b'ofcourse'\n",
      "        out_of_vocabulary_words_list[6] = b'..go'\n",
      "        out_of_vocabulary_words_list[7] = b'..this'\n",
      "        out_of_vocabulary_words_list[8] = b'suxxxxxxxxxxxxxxxxxxxxxx'\n",
      "        out_of_vocabulary_words_list[9] = b'e2252'\n",
      "        out_of_vocabulary_words_list[10] = b'monkeypatch'\n",
      "        out_of_vocabulary_words_list[11] = b'mssql'\n",
      "        out_of_vocabulary_words_list[12] = b'eccoboard\\xe2\\x84\\xa2'\n",
      "        out_of_vocabulary_words_list[13] = b'bmw-mercedes'\n",
      "        out_of_vocabulary_words_list[14] = b'goung'\n",
      "        out_of_vocabulary_words_list[15] = b'head-'\n",
      "        out_of_vocabulary_words_list[16] = b'jumbo-shrimp'\n",
      "        out_of_vocabulary_words_list[17] = b'discount-lexus'\n",
      "        out_of_vocabulary_words_list[18] = b'quicker-than-a-cayman'\n",
      "        out_of_vocabulary_words_list[19] = b\"cat's-meow\"\n",
      "        out_of_vocabulary_words_list[20] = b'current-season'\n",
      "        out_of_vocabulary_words_list[21] = b'all-plastic'\n",
      "        out_of_vocabulary_words_list[22] = b'fan-friendly'\n",
      "        out_of_vocabulary_words_list[23] = b'siginificantly'\n",
      "        out_of_vocabulary_words_list[24] = b'games.as'\n",
      "        out_of_vocabulary_words_list[25] = b'for.so'\n",
      "        out_of_vocabulary_words_list[26] = b'power/graphics'\n",
      "        out_of_vocabulary_words_list[27] = b'nv3500'\n",
      "        out_of_vocabulary_words_list[28] = b'350c'\n",
      "        out_of_vocabulary_words_list[29] = b'gretest'\n",
      "        out_of_vocabulary_words_list[30] = b'intoduced'\n",
      "        out_of_vocabulary_words_list[31] = b'mw2'\n",
      "        out_of_vocabulary_words_list[32] = b'yet.it'\n",
      "        out_of_vocabulary_words_list[33] = b'incredebly'\n",
      "        out_of_vocabulary_words_list[34] = b'5000000000000'\n",
      "        out_of_vocabulary_words_list[35] = b'fire-power'\n",
      "        out_of_vocabulary_words_list[36] = b'o3d'\n",
      "        out_of_vocabulary_words_list[37] = b'300x'\n",
      "        out_of_vocabulary_words_list[38] = b'frats'\n",
      "        out_of_vocabulary_words_list[39] = b'jaronczyk'\n",
      "        out_of_vocabulary_words_list[40] = b'import-intenders'\n",
      "        out_of_vocabulary_words_list[41] = b'stodgy-looking'\n",
      "        out_of_vocabulary_words_list[42] = b'sloppy-handling'\n",
      "        out_of_vocabulary_words_list[43] = b'platform-sharing'\n",
      "        out_of_vocabulary_words_list[44] = b'all-weather-wood'\n",
      "        out_of_vocabulary_words_list[45] = b'awwf'\n",
      "        out_of_vocabulary_words_list[46] = b'maniculatus'\n",
      "        out_of_vocabulary_words_list[47] = b'rdbsm'\n",
      "        out_of_vocabulary_words_list[48] = b'hardibacker'\n",
      "        out_of_vocabulary_words_list[49] = b'cement/gypsum'\n",
      "        out_of_vocabulary_words_list[50] = b'atii'\n",
      " -- len(out_of_vocabulary_words_list) = 735\n",
      " -- original_words_num = 7013\n",
      " -- lowercase_words_num = 1\n",
      " -- zero_digits_replaced_num = 4\n",
      " -- zero_digits_replaced_lowercase_num = 0\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 7\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7}\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58639.0    2722.0    2863.0     792.0     165.0      22.0      21.0    2226.0\n",
      "  B-OTHOBJ       0.0    2713.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2560.0       8.0       0.0       4.0       3.0       0.0       0.0     341.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -1.1      -1.1      -0.9      -1.0      -1.0      -1.1      -1.0      -1.0\n",
      "  B-OTHOBJ   -9999.0      -1.0   -9999.0      -1.0      -1.2      -0.9   -9999.0   -9999.0      -0.9\n",
      "  B-ASPOBJ   -9999.0      -0.9      -1.0   -9999.0      -1.0      -0.8   -9999.0   -9999.0      -1.0\n",
      "     B-ASP   -9999.0      -1.1      -1.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0      -1.1\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -1.1      -0.9      -1.0   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -1.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 0/100 \"f1-alpha-match-10\" train / dev / test | 3.48 / 3.55 / 3.55.\n",
      "## [BEST epoch], 11 seconds.\n",
      "\n",
      "-- train epoch 1/100, batch 261/261 (100.00%), loss = 709.25.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 1/100 \"f1-alpha-match-10\" train / dev / test | 60.42 / 59.59 / 59.59.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 2/100, batch 261/261 (100.00%), loss = 394.92.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 2/100 \"f1-alpha-match-10\" train / dev / test | 69.55 / 66.87 / 66.87.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 3/100, batch 261/261 (100.00%), loss = 341.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 3/100 \"f1-alpha-match-10\" train / dev / test | 72.22 / 67.51 / 67.51.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 4/100, batch 261/261 (100.00%), loss = 328.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 4/100 \"f1-alpha-match-10\" train / dev / test | 74.17 / 71.47 / 71.47.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 5/100, batch 261/261 (100.00%), loss = 305.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 5/100 \"f1-alpha-match-10\" train / dev / test | 75.36 / 72.44 / 72.44.\n",
      "## [BEST epoch], 74 seconds.\n",
      "\n",
      "-- train epoch 6/100, batch 261/261 (100.00%), loss = 301.25.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 6/100 \"f1-alpha-match-10\" train / dev / test | 77.64 / 76.34 / 76.34.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 7/100, batch 261/261 (100.00%), loss = 250.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 7/100 \"f1-alpha-match-10\" train / dev / test | 76.98 / 75.18 / 75.18.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.34), 71 seconds].\n",
      "\n",
      "-- train epoch 8/100, batch 261/261 (100.00%), loss = 220.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 8/100 \"f1-alpha-match-10\" train / dev / test | 79.53 / 77.39 / 77.39.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 9/100, batch 261/261 (100.00%), loss = 221.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 9/100 \"f1-alpha-match-10\" train / dev / test | 80.71 / 78.51 / 78.51.\n",
      "## [BEST epoch], 74 seconds.\n",
      "\n",
      "-- train epoch 10/100, batch 261/261 (100.00%), loss = 228.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 10/100 \"f1-alpha-match-10\" train / dev / test | 80.51 / 78.53 / 78.53.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 11/100, batch 261/261 (100.00%), loss = 198.93.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 11/100 \"f1-alpha-match-10\" train / dev / test | 81.92 / 78.74 / 78.74.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 12/100, batch 261/261 (100.00%), loss = 221.02.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 12/100 \"f1-alpha-match-10\" train / dev / test | 84.32 / 80.58 / 80.58.\n",
      "## [BEST epoch], 72 seconds.\n",
      "\n",
      "-- train epoch 13/100, batch 261/261 (100.00%), loss = 199.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 13/100 \"f1-alpha-match-10\" train / dev / test | 84.21 / 80.75 / 80.75.\n",
      "## [BEST epoch], 72 seconds.\n",
      "\n",
      "-- train epoch 14/100, batch 261/261 (100.00%), loss = 181.75.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 14/100 \"f1-alpha-match-10\" train / dev / test | 83.41 / 80.27 / 80.27.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.75), 63 seconds].\n",
      "\n",
      "-- train epoch 15/100, batch 261/261 (100.00%), loss = 153.56.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 15/100 \"f1-alpha-match-10\" train / dev / test | 84.70 / 81.14 / 81.14.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 16/100, batch 261/261 (100.00%), loss = 190.08.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 16/100 \"f1-alpha-match-10\" train / dev / test | 85.51 / 82.05 / 82.05.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 17/100, batch 261/261 (100.00%), loss = 179.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 17/100 \"f1-alpha-match-10\" train / dev / test | 85.87 / 82.06 / 82.06.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 18/100, batch 261/261 (100.00%), loss = 188.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 18/100 \"f1-alpha-match-10\" train / dev / test | 86.33 / 82.51 / 82.51.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 19/100, batch 261/261 (100.00%), loss = 138.68.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 19/100 \"f1-alpha-match-10\" train / dev / test | 86.83 / 82.65 / 82.65.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 20/100, batch 261/261 (100.00%), loss = 152.09.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 20/100 \"f1-alpha-match-10\" train / dev / test | 87.10 / 82.42 / 82.42.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.65), 72 seconds].\n",
      "\n",
      "-- train epoch 21/100, batch 261/261 (100.00%), loss = 160.41.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 21/100 \"f1-alpha-match-10\" train / dev / test | 87.50 / 82.73 / 82.73.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 22/100, batch 261/261 (100.00%), loss = 171.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 22/100 \"f1-alpha-match-10\" train / dev / test | 87.50 / 82.93 / 82.93.\n",
      "## [BEST epoch], 68 seconds.\n",
      "\n",
      "-- train epoch 23/100, batch 261/261 (100.00%), loss = 157.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 23/100 \"f1-alpha-match-10\" train / dev / test | 89.01 / 82.67 / 82.67.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.93), 68 seconds].\n",
      "\n",
      "-- train epoch 24/100, batch 261/261 (100.00%), loss = 148.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 24/100 \"f1-alpha-match-10\" train / dev / test | 88.11 / 81.74 / 81.74.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.93), 69 seconds].\n",
      "\n",
      "-- train epoch 25/100, batch 261/261 (100.00%), loss = 142.88.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 25/100 \"f1-alpha-match-10\" train / dev / test | 89.19 / 83.50 / 83.50.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 26/100, batch 261/261 (100.00%), loss = 129.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 26/100 \"f1-alpha-match-10\" train / dev / test | 89.51 / 83.66 / 83.66.\n",
      "## [BEST epoch], 71 seconds.\n",
      "\n",
      "-- train epoch 27/100, batch 261/261 (100.00%), loss = 123.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 27/100 \"f1-alpha-match-10\" train / dev / test | 88.88 / 82.74 / 82.74.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.66), 68 seconds].\n",
      "\n",
      "-- train epoch 28/100, batch 261/261 (100.00%), loss = 122.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 28/100 \"f1-alpha-match-10\" train / dev / test | 89.96 / 83.32 / 83.32.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.66), 62 seconds].\n",
      "\n",
      "-- train epoch 29/100, batch 261/261 (100.00%), loss = 133.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 29/100 \"f1-alpha-match-10\" train / dev / test | 89.92 / 83.82 / 83.82.\n",
      "## [BEST epoch], 69 seconds.\n",
      "\n",
      "-- train epoch 30/100, batch 261/261 (100.00%), loss = 123.55.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 30/100 \"f1-alpha-match-10\" train / dev / test | 90.04 / 82.99 / 82.99.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.82), 64 seconds].\n",
      "\n",
      "-- train epoch 31/100, batch 261/261 (100.00%), loss = 112.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 31/100 \"f1-alpha-match-10\" train / dev / test | 90.58 / 83.10 / 83.10.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.82), 64 seconds].\n",
      "\n",
      "-- train epoch 32/100, batch 261/261 (100.00%), loss = 99.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 32/100 \"f1-alpha-match-10\" train / dev / test | 90.62 / 83.30 / 83.30.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=83.82), 63 seconds].\n",
      "\n",
      "-- train epoch 33/100, batch 261/261 (100.00%), loss = 121.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 33/100 \"f1-alpha-match-10\" train / dev / test | 90.76 / 82.75 / 82.75.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=83.82), 66 seconds].\n",
      "\n",
      "-- train epoch 34/100, batch 261/261 (100.00%), loss = 102.97.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 34/100 \"f1-alpha-match-10\" train / dev / test | 91.08 / 82.92 / 82.92.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=83.82), 69 seconds].\n",
      "\n",
      "-- train epoch 35/100, batch 261/261 (100.00%), loss = 119.15.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 35/100 \"f1-alpha-match-10\" train / dev / test | 91.61 / 82.79 / 82.79.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=83.82), 70 seconds].\n",
      "\n",
      "-- train epoch 36/100, batch 261/261 (100.00%), loss = 110.34.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 36/100 \"f1-alpha-match-10\" train / dev / test | 91.58 / 83.79 / 83.79.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=83.82), 69 seconds].\n",
      "\n",
      "-- train epoch 37/100, batch 261/261 (100.00%), loss = 121.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 37/100 \"f1-alpha-match-10\" train / dev / test | 91.49 / 82.79 / 82.79.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=83.82), 70 seconds].\n",
      "\n",
      "-- train epoch 38/100, batch 261/261 (100.00%), loss = 114.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 38/100 \"f1-alpha-match-10\" train / dev / test | 92.35 / 83.30 / 83.30.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=83.82), 73 seconds].\n",
      "\n",
      "-- train epoch 39/100, batch 261/261 (100.00%), loss = 117.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 39/100 \"f1-alpha-match-10\" train / dev / test | 92.31 / 84.83 / 84.83.\n",
      "## [BEST epoch], 73 seconds.\n",
      "\n",
      "-- train epoch 40/100, batch 261/261 (100.00%), loss = 97.10.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 40/100 \"f1-alpha-match-10\" train / dev / test | 92.69 / 83.19 / 83.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 41/100, batch 261/261 (100.00%), loss = 94.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 41/100 \"f1-alpha-match-10\" train / dev / test | 92.77 / 84.27 / 84.27.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=84.83), 67 seconds].\n",
      "\n",
      "-- train epoch 42/100, batch 261/261 (100.00%), loss = 113.93.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 42/100 \"f1-alpha-match-10\" train / dev / test | 92.10 / 82.92 / 82.92.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=84.83), 70 seconds].\n",
      "\n",
      "-- train epoch 43/100, batch 261/261 (100.00%), loss = 95.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 43/100 \"f1-alpha-match-10\" train / dev / test | 92.90 / 83.62 / 83.62.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 44/100, batch 261/261 (100.00%), loss = 96.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 44/100 \"f1-alpha-match-10\" train / dev / test | 93.39 / 84.31 / 84.31.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=84.83), 68 seconds].\n",
      "\n",
      "-- train epoch 45/100, batch 261/261 (100.00%), loss = 96.02.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 45/100 \"f1-alpha-match-10\" train / dev / test | 93.06 / 83.96 / 83.96.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 46/100, batch 261/261 (100.00%), loss = 108.50.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 46/100 \"f1-alpha-match-10\" train / dev / test | 93.27 / 84.47 / 84.47.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 47/100, batch 261/261 (100.00%), loss = 106.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 47/100 \"f1-alpha-match-10\" train / dev / test | 93.14 / 84.07 / 84.07.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=84.83), 72 seconds].\n",
      "\n",
      "-- train epoch 48/100, batch 261/261 (100.00%), loss = 102.06.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 48/100 \"f1-alpha-match-10\" train / dev / test | 93.64 / 84.04 / 84.04.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 49/100, batch 261/261 (100.00%), loss = 97.60.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 49/100 \"f1-alpha-match-10\" train / dev / test | 94.11 / 84.24 / 84.24.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=84.83), 69 seconds].\n",
      "\n",
      "-- train epoch 50/100, batch 261/261 (100.00%), loss = 92.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 50/100 \"f1-alpha-match-10\" train / dev / test | 93.97 / 84.08 / 84.08.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=84.83), 67 seconds].\n",
      "\n",
      "-- train epoch 51/100, batch 261/261 (100.00%), loss = 91.43.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 51/100 \"f1-alpha-match-10\" train / dev / test | 94.32 / 85.04 / 85.04.\n",
      "## [BEST epoch], 70 seconds.\n",
      "\n",
      "-- train epoch 52/100, batch 261/261 (100.00%), loss = 88.85.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 52/100 \"f1-alpha-match-10\" train / dev / test | 94.63 / 85.07 / 85.07.\n",
      "## [BEST epoch], 67 seconds.\n",
      "\n",
      "-- train epoch 53/100, batch 261/261 (100.00%), loss = 73.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 53/100 \"f1-alpha-match-10\" train / dev / test | 93.51 / 84.07 / 84.07.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 54/100, batch 261/261 (100.00%), loss = 94.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 54/100 \"f1-alpha-match-10\" train / dev / test | 94.92 / 84.98 / 84.98.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=85.07), 73 seconds].\n",
      "\n",
      "-- train epoch 55/100, batch 261/261 (100.00%), loss = 90.98.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 55/100 \"f1-alpha-match-10\" train / dev / test | 94.52 / 84.40 / 84.40.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=85.07), 72 seconds].\n",
      "\n",
      "-- train epoch 56/100, batch 261/261 (100.00%), loss = 69.39.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 56/100 \"f1-alpha-match-10\" train / dev / test | 94.66 / 84.66 / 84.66.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 57/100, batch 261/261 (100.00%), loss = 81.71.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 57/100 \"f1-alpha-match-10\" train / dev / test | 94.62 / 85.06 / 85.06.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 58/100, batch 261/261 (100.00%), loss = 78.84.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 58/100 \"f1-alpha-match-10\" train / dev / test | 94.92 / 83.56 / 83.56.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 59/100, batch 261/261 (100.00%), loss = 83.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 59/100 \"f1-alpha-match-10\" train / dev / test | 94.87 / 84.47 / 84.47.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 60/100, batch 261/261 (100.00%), loss = 82.65.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 60/100 \"f1-alpha-match-10\" train / dev / test | 95.05 / 84.93 / 84.93.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=85.07), 70 seconds].\n",
      "\n",
      "-- train epoch 61/100, batch 261/261 (100.00%), loss = 64.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 61/100 \"f1-alpha-match-10\" train / dev / test | 95.02 / 84.74 / 84.74.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 62/100, batch 261/261 (100.00%), loss = 90.81.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 62/100 \"f1-alpha-match-10\" train / dev / test | 94.59 / 84.58 / 84.58.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 63/100, batch 261/261 (100.00%), loss = 77.32.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 63/100 \"f1-alpha-match-10\" train / dev / test | 95.50 / 84.52 / 84.52.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 64/100, batch 261/261 (100.00%), loss = 86.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 64/100 \"f1-alpha-match-10\" train / dev / test | 95.48 / 84.06 / 84.06.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 65/100, batch 261/261 (100.00%), loss = 65.77.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 65/100 \"f1-alpha-match-10\" train / dev / test | 95.64 / 84.29 / 84.29.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=85.07), 64 seconds].\n",
      "\n",
      "-- train epoch 66/100, batch 261/261 (100.00%), loss = 82.67.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 66/100 \"f1-alpha-match-10\" train / dev / test | 95.49 / 84.61 / 84.61.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=85.07), 68 seconds].\n",
      "\n",
      "-- train epoch 67/100, batch 261/261 (100.00%), loss = 78.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 67/100 \"f1-alpha-match-10\" train / dev / test | 95.16 / 84.77 / 84.77.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 68/100, batch 261/261 (100.00%), loss = 80.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 68/100 \"f1-alpha-match-10\" train / dev / test | 95.31 / 84.56 / 84.56.\n",
      "## [no improvement micro-f1 on DEV during the last 16 epochs (best_f1_dev=85.07), 64 seconds].\n",
      "\n",
      "-- train epoch 69/100, batch 261/261 (100.00%), loss = 72.96.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 69/100 \"f1-alpha-match-10\" train / dev / test | 95.56 / 84.60 / 84.60.\n",
      "## [no improvement micro-f1 on DEV during the last 17 epochs (best_f1_dev=85.07), 66 seconds].\n",
      "\n",
      "-- train epoch 70/100, batch 261/261 (100.00%), loss = 79.23.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 70/100 \"f1-alpha-match-10\" train / dev / test | 95.49 / 84.55 / 84.55.\n",
      "## [no improvement micro-f1 on DEV during the last 18 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "-- train epoch 71/100, batch 261/261 (100.00%), loss = 71.18.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 71/100 \"f1-alpha-match-10\" train / dev / test | 95.55 / 84.34 / 84.34.\n",
      "## [no improvement micro-f1 on DEV during the last 19 epochs (best_f1_dev=85.07), 71 seconds].\n",
      "\n",
      "-- train epoch 72/100, batch 261/261 (100.00%), loss = 68.98.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 72/100 \"f1-alpha-match-10\" train / dev / test | 95.71 / 84.57 / 84.57.\n",
      "## [no improvement micro-f1 on DEV during the last 20 epochs (best_f1_dev=85.07), 65 seconds].\n",
      "\n",
      "-- train epoch 73/100, batch 261/261 (100.00%), loss = 63.54.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "\n",
      "++ predicting, batch 5/5 (80.00%).\n",
      "== eval epoch 73/100 \"f1-alpha-match-10\" train / dev / test | 95.56 / 84.14 / 84.14.\n",
      "## [no improvement micro-f1 on DEV during the last 21 epochs (best_f1_dev=85.07), 69 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv'\n",
      "dropout_ratio=0.5\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=100\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_08_22_12-07_55_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='BiRNNCFR.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           3.48 |           3.55 |           3.55 \n",
      "              1 |         709.25 |          60.42 |          59.59 |          59.59 \n",
      "              2 |         394.92 |          69.55 |          66.87 |          66.87 \n",
      "              3 |         341.32 |          72.22 |          67.51 |          67.51 \n",
      "              4 |         328.28 |          74.17 |          71.47 |          71.47 \n",
      "              5 |         305.78 |          75.36 |          72.44 |          72.44 \n",
      "              6 |         301.25 |          77.64 |          76.34 |          76.34 \n",
      "              7 |         250.16 |          76.98 |          75.18 |          75.18 \n",
      "              8 |         220.17 |          79.53 |          77.39 |          77.39 \n",
      "              9 |         221.51 |          80.71 |          78.51 |          78.51 \n",
      "             10 |         228.58 |          80.51 |          78.53 |          78.53 \n",
      "             11 |         198.93 |          81.92 |          78.74 |          78.74 \n",
      "             12 |         221.02 |          84.32 |          80.58 |          80.58 \n",
      "             13 |         199.78 |          84.21 |          80.75 |          80.75 \n",
      "             14 |         181.75 |          83.41 |          80.27 |          80.27 \n",
      "             15 |         153.56 |          84.70 |          81.14 |          81.14 \n",
      "             16 |         190.08 |          85.51 |          82.05 |          82.05 \n",
      "             17 |         179.52 |          85.87 |          82.06 |          82.06 \n",
      "             18 |         188.47 |          86.33 |          82.51 |          82.51 \n",
      "             19 |         138.68 |          86.83 |          82.65 |          82.65 \n",
      "             20 |         152.09 |          87.10 |          82.42 |          82.42 \n",
      "             21 |         160.41 |          87.50 |          82.73 |          82.73 \n",
      "             22 |         171.16 |          87.50 |          82.93 |          82.93 \n",
      "             23 |         157.21 |          89.01 |          82.67 |          82.67 \n",
      "             24 |         148.83 |          88.11 |          81.74 |          81.74 \n",
      "             25 |         142.88 |          89.19 |          83.50 |          83.50 \n",
      "             26 |         129.07 |          89.51 |          83.66 |          83.66 \n",
      "             27 |         123.05 |          88.88 |          82.74 |          82.74 \n",
      "             28 |         122.57 |          89.96 |          83.32 |          83.32 \n",
      "             29 |         133.82 |          89.92 |          83.82 |          83.82 \n",
      "             30 |         123.55 |          90.04 |          82.99 |          82.99 \n",
      "             31 |         112.52 |          90.58 |          83.10 |          83.10 \n",
      "             32 |          99.79 |          90.62 |          83.30 |          83.30 \n",
      "             33 |         121.00 |          90.76 |          82.75 |          82.75 \n",
      "             34 |         102.97 |          91.08 |          82.92 |          82.92 \n",
      "             35 |         119.15 |          91.61 |          82.79 |          82.79 \n",
      "             36 |         110.34 |          91.58 |          83.79 |          83.79 \n",
      "             37 |         121.83 |          91.49 |          82.79 |          82.79 \n",
      "             38 |         114.21 |          92.35 |          83.30 |          83.30 \n",
      "             39 |         117.00 |          92.31 |          84.83 |          84.83 \n",
      "             40 |          97.10 |          92.69 |          83.19 |          83.19 \n",
      "             41 |          94.96 |          92.77 |          84.27 |          84.27 \n",
      "             42 |         113.93 |          92.10 |          82.92 |          82.92 \n",
      "             43 |          95.82 |          92.90 |          83.62 |          83.62 \n",
      "             44 |          96.58 |          93.39 |          84.31 |          84.31 \n",
      "             45 |          96.02 |          93.06 |          83.96 |          83.96 \n",
      "             46 |         108.50 |          93.27 |          84.47 |          84.47 \n",
      "             47 |         106.51 |          93.14 |          84.07 |          84.07 \n",
      "             48 |         102.06 |          93.64 |          84.04 |          84.04 \n",
      "             49 |          97.60 |          94.11 |          84.24 |          84.24 \n",
      "             50 |          92.51 |          93.97 |          84.08 |          84.08 \n",
      "             51 |          91.43 |          94.32 |          85.04 |          85.04 \n",
      "             52 |          88.85 |          94.63 |          85.07 |          85.07 \n",
      "             53 |          73.28 |          93.51 |          84.07 |          84.07 \n",
      "             54 |          94.17 |          94.92 |          84.98 |          84.98 \n",
      "             55 |          90.98 |          94.52 |          84.40 |          84.40 \n",
      "             56 |          69.39 |          94.66 |          84.66 |          84.66 \n",
      "             57 |          81.71 |          94.62 |          85.06 |          85.06 \n",
      "             58 |          78.84 |          94.92 |          83.56 |          83.56 \n",
      "             59 |          83.32 |          94.87 |          84.47 |          84.47 \n",
      "             60 |          82.65 |          95.05 |          84.93 |          84.93 \n",
      "             61 |          64.26 |          95.02 |          84.74 |          84.74 \n",
      "             62 |          90.81 |          94.59 |          84.58 |          84.58 \n",
      "             63 |          77.32 |          95.50 |          84.52 |          84.52 \n",
      "             64 |          86.82 |          95.48 |          84.06 |          84.06 \n",
      "             65 |          65.77 |          95.64 |          84.29 |          84.29 \n",
      "             66 |          82.67 |          95.49 |          84.61 |          84.61 \n",
      "             67 |          78.83 |          95.16 |          84.77 |          84.77 \n",
      "             68 |          80.57 |          95.31 |          84.56 |          84.56 \n",
      "             69 |          72.96 |          95.56 |          84.60 |          84.60 \n",
      "             70 |          79.23 |          95.49 |          84.55 |          84.55 \n",
      "             71 |          71.18 |          95.55 |          84.34 |          84.34 \n",
      "             72 |          68.98 |          95.71 |          84.57 |          84.57 \n",
      "             73 |          63.54 |          95.56 |          84.14 |          84.14 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 52, f1-alpha-match-10, test = 85.07)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 85.07, precision = 87.37, recall = 82.89\n",
      "*** TP = 1114, FP = 161, FN = 230\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNNCRF --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv --save BiRNNCFR.hdf5\n",
      "\n",
      "85.0706\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv\" --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --model BiRNNCRF --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_test.csv\" --save \"BiRNNCFR.hdf5\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv: 2619 samples, 74616 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv: 63 samples, 322 words.\n",
      "DatasetsBank: len(unique_words_list) = 7143 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7600 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7604 unique words.\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 7\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7}\n",
      "in main\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "init targer base\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "elmo is initiated\n",
      "init targer BiRNNCNNCRF\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58639.0    2722.0    2863.0     792.0     165.0      22.0      21.0    2226.0\n",
      "  B-OTHOBJ       0.0    2713.0       0.0       1.0       3.0       1.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2560.0       8.0       0.0       4.0       3.0       0.0       0.0     341.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -1.0      -0.9      -1.1      -1.0      -1.1      -1.1      -1.0      -1.0\n",
      "  B-OTHOBJ   -9999.0      -1.0   -9999.0      -0.8      -1.1      -1.1   -9999.0   -9999.0      -1.1\n",
      "  B-ASPOBJ   -9999.0      -1.0      -1.0   -9999.0      -1.2      -0.9   -9999.0   -9999.0      -0.9\n",
      "     B-ASP   -9999.0      -1.0      -0.8      -1.1   -9999.0   -9999.0   -9999.0   -9999.0      -1.0\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -1.1      -1.0      -0.9   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 0/50 \"f1-alpha-match-10\" train / dev / test | 4.90 / 4.60 / 12.08.\n",
      "## [BEST epoch], 16 seconds.\n",
      "\n",
      "-- train epoch 1/50, batch 261/261 (100.00%), loss = 482.29.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 1/50 \"f1-alpha-match-10\" train / dev / test | 60.09 / 58.18 / 44.87.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 2/50, batch 261/261 (100.00%), loss = 297.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 2/50 \"f1-alpha-match-10\" train / dev / test | 63.26 / 58.87 / 42.55.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 3/50, batch 261/261 (100.00%), loss = 271.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 3/50 \"f1-alpha-match-10\" train / dev / test | 68.38 / 64.74 / 46.43.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 4/50, batch 261/261 (100.00%), loss = 246.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 4/50 \"f1-alpha-match-10\" train / dev / test | 70.43 / 64.01 / 34.43.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=64.74), 106 seconds].\n",
      "\n",
      "-- train epoch 5/50, batch 261/261 (100.00%), loss = 234.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 5/50 \"f1-alpha-match-10\" train / dev / test | 72.03 / 67.81 / 45.49.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 6/50, batch 261/261 (100.00%), loss = 197.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 6/50 \"f1-alpha-match-10\" train / dev / test | 76.58 / 70.35 / 45.19.\n",
      "## [BEST epoch], 96 seconds.\n",
      "\n",
      "-- train epoch 7/50, batch 261/261 (100.00%), loss = 182.52.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 7/50 \"f1-alpha-match-10\" train / dev / test | 77.64 / 70.21 / 45.28.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=70.35), 99 seconds].\n",
      "\n",
      "-- train epoch 8/50, batch 261/261 (100.00%), loss = 193.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 8/50 \"f1-alpha-match-10\" train / dev / test | 79.05 / 72.93 / 50.97.\n",
      "## [BEST epoch], 98 seconds.\n",
      "\n",
      "-- train epoch 9/50, batch 261/261 (100.00%), loss = 183.23.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 9/50 \"f1-alpha-match-10\" train / dev / test | 82.60 / 76.35 / 42.69.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 10/50, batch 261/261 (100.00%), loss = 157.00.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 10/50 \"f1-alpha-match-10\" train / dev / test | 81.92 / 74.99 / 42.97.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.35), 101 seconds].\n",
      "\n",
      "-- train epoch 11/50, batch 261/261 (100.00%), loss = 152.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 11/50 \"f1-alpha-match-10\" train / dev / test | 83.08 / 76.47 / 42.80.\n",
      "## [BEST epoch], 106 seconds.\n",
      "\n",
      "-- train epoch 12/50, batch 261/261 (100.00%), loss = 127.66.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 12/50 \"f1-alpha-match-10\" train / dev / test | 83.59 / 76.03 / 40.34.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=76.47), 102 seconds].\n",
      "\n",
      "-- train epoch 13/50, batch 261/261 (100.00%), loss = 132.64.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 13/50 \"f1-alpha-match-10\" train / dev / test | 85.58 / 77.95 / 34.75.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 14/50, batch 261/261 (100.00%), loss = 130.28.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 14/50 \"f1-alpha-match-10\" train / dev / test | 84.71 / 78.42 / 48.19.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 15/50, batch 261/261 (100.00%), loss = 120.01.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 15/50 \"f1-alpha-match-10\" train / dev / test | 85.55 / 78.11 / 49.41.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=78.42), 103 seconds].\n",
      "\n",
      "-- train epoch 16/50, batch 261/261 (100.00%), loss = 134.78.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 16/50 \"f1-alpha-match-10\" train / dev / test | 88.04 / 79.42 / 46.04.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 17/50, batch 261/261 (100.00%), loss = 124.69.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 17/50 \"f1-alpha-match-10\" train / dev / test | 88.31 / 78.95 / 42.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.42), 97 seconds].\n",
      "\n",
      "-- train epoch 18/50, batch 261/261 (100.00%), loss = 137.27.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 18/50 \"f1-alpha-match-10\" train / dev / test | 88.30 / 80.43 / 38.06.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 19/50, batch 261/261 (100.00%), loss = 88.62.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 19/50 \"f1-alpha-match-10\" train / dev / test | 89.44 / 79.88 / 32.92.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.43), 102 seconds].\n",
      "\n",
      "-- train epoch 20/50, batch 261/261 (100.00%), loss = 85.18.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 20/50 \"f1-alpha-match-10\" train / dev / test | 90.75 / 81.99 / 41.27.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 21/50, batch 261/261 (100.00%), loss = 107.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 21/50 \"f1-alpha-match-10\" train / dev / test | 89.94 / 80.27 / 34.78.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=81.99), 103 seconds].\n",
      "\n",
      "-- train epoch 22/50, batch 261/261 (100.00%), loss = 120.54.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 22/50 \"f1-alpha-match-10\" train / dev / test | 90.99 / 81.55 / 39.66.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 23/50, batch 261/261 (100.00%), loss = 103.42.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 23/50 \"f1-alpha-match-10\" train / dev / test | 91.88 / 81.28 / 44.36.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 24/50, batch 261/261 (100.00%), loss = 94.27.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 24/50 \"f1-alpha-match-10\" train / dev / test | 91.23 / 79.44 / 44.26.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 25/50, batch 261/261 (100.00%), loss = 90.57.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 25/50 \"f1-alpha-match-10\" train / dev / test | 92.44 / 80.88 / 48.00.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=81.99), 98 seconds].\n",
      "\n",
      "-- train epoch 26/50, batch 261/261 (100.00%), loss = 74.31.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 26/50 \"f1-alpha-match-10\" train / dev / test | 92.19 / 80.35 / 45.45.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 27/50, batch 261/261 (100.00%), loss = 79.91.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 27/50 \"f1-alpha-match-10\" train / dev / test | 92.21 / 80.28 / 47.88.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=81.99), 96 seconds].\n",
      "\n",
      "-- train epoch 28/50, batch 261/261 (100.00%), loss = 86.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 28/50 \"f1-alpha-match-10\" train / dev / test | 93.30 / 81.06 / 43.33.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=81.99), 97 seconds].\n",
      "\n",
      "-- train epoch 29/50, batch 261/261 (100.00%), loss = 79.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 29/50 \"f1-alpha-match-10\" train / dev / test | 92.80 / 81.12 / 43.65.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=81.99), 102 seconds].\n",
      "\n",
      "-- train epoch 30/50, batch 261/261 (100.00%), loss = 79.53.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 30/50 \"f1-alpha-match-10\" train / dev / test | 93.12 / 81.97 / 45.45.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=81.99), 99 seconds].\n",
      "\n",
      "-- train epoch 31/50, batch 261/261 (100.00%), loss = 71.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 31/50 \"f1-alpha-match-10\" train / dev / test | 94.07 / 82.15 / 41.43.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 32/50, batch 261/261 (100.00%), loss = 47.15.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 32/50 \"f1-alpha-match-10\" train / dev / test | 94.20 / 82.37 / 38.89.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 33/50, batch 261/261 (100.00%), loss = 64.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 33/50 \"f1-alpha-match-10\" train / dev / test | 93.03 / 81.21 / 47.19.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 34/50, batch 261/261 (100.00%), loss = 51.36.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 34/50 \"f1-alpha-match-10\" train / dev / test | 94.08 / 81.68 / 44.44.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 35/50, batch 261/261 (100.00%), loss = 69.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 35/50 \"f1-alpha-match-10\" train / dev / test | 94.54 / 81.42 / 46.64.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 36/50, batch 261/261 (100.00%), loss = 61.80.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 36/50 \"f1-alpha-match-10\" train / dev / test | 94.93 / 80.98 / 46.88.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.37), 95 seconds].\n",
      "\n",
      "-- train epoch 37/50, batch 261/261 (100.00%), loss = 77.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 37/50 \"f1-alpha-match-10\" train / dev / test | 94.04 / 81.85 / 43.92.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 38/50, batch 261/261 (100.00%), loss = 67.29.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 38/50 \"f1-alpha-match-10\" train / dev / test | 94.54 / 81.54 / 41.60.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 39/50, batch 261/261 (100.00%), loss = 70.26.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 39/50 \"f1-alpha-match-10\" train / dev / test | 94.75 / 82.11 / 41.32.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 40/50, batch 261/261 (100.00%), loss = 61.19.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 40/50 \"f1-alpha-match-10\" train / dev / test | 95.10 / 81.77 / 38.40.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=82.37), 101 seconds].\n",
      "\n",
      "-- train epoch 41/50, batch 261/261 (100.00%), loss = 48.37.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 41/50 \"f1-alpha-match-10\" train / dev / test | 95.26 / 81.73 / 38.91.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=82.37), 96 seconds].\n",
      "\n",
      "-- train epoch 42/50, batch 261/261 (100.00%), loss = 65.36.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 42/50 \"f1-alpha-match-10\" train / dev / test | 95.11 / 81.01 / 37.45.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 43/50, batch 261/261 (100.00%), loss = 44.95.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 43/50 \"f1-alpha-match-10\" train / dev / test | 95.16 / 82.13 / 37.94.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=82.37), 97 seconds].\n",
      "\n",
      "-- train epoch 44/50, batch 261/261 (100.00%), loss = 49.34.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 44/50 \"f1-alpha-match-10\" train / dev / test | 95.17 / 81.70 / 42.47.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 45/50, batch 261/261 (100.00%), loss = 52.43.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 45/50 \"f1-alpha-match-10\" train / dev / test | 95.61 / 81.37 / 34.24.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=82.37), 98 seconds].\n",
      "\n",
      "-- train epoch 46/50, batch 261/261 (100.00%), loss = 70.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 46/50 \"f1-alpha-match-10\" train / dev / test | 95.10 / 81.02 / 41.86.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=82.37), 99 seconds].\n",
      "\n",
      "-- train epoch 47/50, batch 261/261 (100.00%), loss = 68.13.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 47/50 \"f1-alpha-match-10\" train / dev / test | 95.54 / 82.24 / 36.58.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=82.37), 100 seconds].\n",
      "\n",
      "-- train epoch 48/50, batch 261/261 (100.00%), loss = 51.89.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 48/50 \"f1-alpha-match-10\" train / dev / test | 95.67 / 80.87 / 41.70.\n",
      "## [no improvement micro-f1 on DEV during the last 16 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 49/50, batch 261/261 (100.00%), loss = 51.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 49/50 \"f1-alpha-match-10\" train / dev / test | 95.84 / 81.43 / 41.30.\n",
      "## [no improvement micro-f1 on DEV during the last 17 epochs (best_f1_dev=82.37), 102 seconds].\n",
      "\n",
      "-- train epoch 50/50, batch 261/261 (100.00%), loss = 66.44.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 50/50 \"f1-alpha-match-10\" train / dev / test | 95.83 / 81.55 / 46.74.\n",
      "## [no improvement micro-f1 on DEV during the last 18 epochs (best_f1_dev=82.37), 95 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv'\n",
      "dropout_ratio=0.5\n",
      "elmo_options='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
      "elmo_weights='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=50\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "isElmo=True\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_09_06_05-34_58_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='new_tagger1.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           4.90 |           4.60 |          12.08 \n",
      "              1 |         482.29 |          60.09 |          58.18 |          44.87 \n",
      "              2 |         297.58 |          63.26 |          58.87 |          42.55 \n",
      "              3 |         271.47 |          68.38 |          64.74 |          46.43 \n",
      "              4 |         246.57 |          70.43 |          64.01 |          34.43 \n",
      "              5 |         234.79 |          72.03 |          67.81 |          45.49 \n",
      "              6 |         197.57 |          76.58 |          70.35 |          45.19 \n",
      "              7 |         182.52 |          77.64 |          70.21 |          45.28 \n",
      "              8 |         193.16 |          79.05 |          72.93 |          50.97 \n",
      "              9 |         183.23 |          82.60 |          76.35 |          42.69 \n",
      "             10 |         157.00 |          81.92 |          74.99 |          42.97 \n",
      "             11 |         152.17 |          83.08 |          76.47 |          42.80 \n",
      "             12 |         127.66 |          83.59 |          76.03 |          40.34 \n",
      "             13 |         132.64 |          85.58 |          77.95 |          34.75 \n",
      "             14 |         130.28 |          84.71 |          78.42 |          48.19 \n",
      "             15 |         120.01 |          85.55 |          78.11 |          49.41 \n",
      "             16 |         134.78 |          88.04 |          79.42 |          46.04 \n",
      "             17 |         124.69 |          88.31 |          78.95 |          42.19 \n",
      "             18 |         137.27 |          88.30 |          80.43 |          38.06 \n",
      "             19 |          88.62 |          89.44 |          79.88 |          32.92 \n",
      "             20 |          85.18 |          90.75 |          81.99 |          41.27 \n",
      "             21 |         107.26 |          89.94 |          80.27 |          34.78 \n",
      "             22 |         120.54 |          90.99 |          81.55 |          39.66 \n",
      "             23 |         103.42 |          91.88 |          81.28 |          44.36 \n",
      "             24 |          94.27 |          91.23 |          79.44 |          44.26 \n",
      "             25 |          90.57 |          92.44 |          80.88 |          48.00 \n",
      "             26 |          74.31 |          92.19 |          80.35 |          45.45 \n",
      "             27 |          79.91 |          92.21 |          80.28 |          47.88 \n",
      "             28 |          86.83 |          93.30 |          81.06 |          43.33 \n",
      "             29 |          79.07 |          92.80 |          81.12 |          43.65 \n",
      "             30 |          79.53 |          93.12 |          81.97 |          45.45 \n",
      "             31 |          71.21 |          94.07 |          82.15 |          41.43 \n",
      "             32 |          47.15 |          94.20 |          82.37 |          38.89 \n",
      "             33 |          64.21 |          93.03 |          81.21 |          47.19 \n",
      "             34 |          51.36 |          94.08 |          81.68 |          44.44 \n",
      "             35 |          69.79 |          94.54 |          81.42 |          46.64 \n",
      "             36 |          61.80 |          94.93 |          80.98 |          46.88 \n",
      "             37 |          77.17 |          94.04 |          81.85 |          43.92 \n",
      "             38 |          67.29 |          94.54 |          81.54 |          41.60 \n",
      "             39 |          70.26 |          94.75 |          82.11 |          41.32 \n",
      "             40 |          61.19 |          95.10 |          81.77 |          38.40 \n",
      "             41 |          48.37 |          95.26 |          81.73 |          38.91 \n",
      "             42 |          65.36 |          95.11 |          81.01 |          37.45 \n",
      "             43 |          44.95 |          95.16 |          82.13 |          37.94 \n",
      "             44 |          49.34 |          95.17 |          81.70 |          42.47 \n",
      "             45 |          52.43 |          95.61 |          81.37 |          34.24 \n",
      "             46 |          70.05 |          95.10 |          81.02 |          41.86 \n",
      "             47 |          68.13 |          95.54 |          82.24 |          36.58 \n",
      "             48 |          51.89 |          95.67 |          80.87 |          41.70 \n",
      "             49 |          51.79 |          95.84 |          81.43 |          41.30 \n",
      "             50 |          66.44 |          95.83 |          81.55 |          46.74 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 32, f1-alpha-match-10, test = 38.89)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 38.89, precision = 51.58, recall = 31.21\n",
      "*** TP = 49, FP = 46, FN = 108\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv --epoch-num 50 --isElmo True --save new_tagger1.hdf5\n",
      "\n",
      "38.8889\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv\" --epoch-num 50 --isElmo True --save \"new_tagger1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args train = /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv: 2668 samples, 74867 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv: 350 samples, 10092 words.\n",
      "Loading from /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv: 63 samples, 322 words.\n",
      "DatasetsBank: len(unique_words_list) = 7144 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7601 unique words.\n",
      "DatasetsBank: len(unique_words_list) = 7604 unique words.\n",
      "\n",
      "load_vocabulary_from_tag_sequences:\n",
      " -- class_num = 8\n",
      " -- {'<pad>': 0, 'O': 1, 'B-OTHOBJ': 2, 'B-ASPOBJ': 3, 'B-ASP': 4, 'I-ASP': 5, 'I-ASPOBJ': 6, 'I-OTHOBJ': 7, 'B ASP': 8}\n",
      "in main\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "init targer base\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "elmo is initiated\n",
      "init targer BiRNNCNNCRF\n",
      "True\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
      "/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
      "Empirical transition matrix from the train dataset:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     B ASP     <sos>\n",
      "\n",
      "     <pad>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "         O       0.0   58686.0    2722.0    2906.0     792.0     165.0      22.0      21.0       6.0    2265.0\n",
      "  B-OTHOBJ       0.0    2762.0       0.0       1.0       3.0       1.0       0.0       0.0       0.0      47.0\n",
      "  B-ASPOBJ       0.0    2587.0       8.0       0.0       4.0       3.0       0.0       0.0      12.0     351.0\n",
      "     B-ASP       0.0     919.0      14.0      28.0       0.0       0.0       0.0       0.0       0.0       5.0\n",
      "     I-ASP       0.0       0.0       0.0       2.0     167.0     307.0       0.0       0.0       0.0       0.0\n",
      "  I-ASPOBJ       0.0       0.0       0.0      22.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "  I-OTHOBJ       0.0       0.0      21.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     B ASP       0.0      12.0       0.0       6.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "     <sos>       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
      "\n",
      "Initialized transition matrix:\n",
      "               <pad>         O  B-OTHOBJ  B-ASPOBJ     B-ASP     I-ASP  I-ASPOBJ  I-OTHOBJ     B ASP     <sos>\n",
      "\n",
      "     <pad>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "         O   -9999.0      -0.8      -0.8      -1.0      -1.1      -0.9      -1.1      -1.0      -1.0      -0.9\n",
      "  B-OTHOBJ   -9999.0      -1.1   -9999.0      -0.9      -0.9      -0.8   -9999.0   -9999.0   -9999.0      -0.8\n",
      "  B-ASPOBJ   -9999.0      -0.8      -1.0   -9999.0      -1.1      -1.1   -9999.0   -9999.0      -1.2      -1.2\n",
      "     B-ASP   -9999.0      -1.1      -1.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0      -1.2\n",
      "     I-ASP   -9999.0   -9999.0   -9999.0      -0.9      -1.0      -1.2   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-ASPOBJ   -9999.0   -9999.0   -9999.0      -1.2   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "  I-OTHOBJ   -9999.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     B ASP   -9999.0      -1.0   -9999.0      -0.9   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "     <sos>   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0   -9999.0\n",
      "\n",
      "Start training...\n",
      "\n",
      "\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 0/50 \"f1-alpha-match-10\" train / dev / test | 2.86 / 3.55 / 8.28.\n",
      "## [BEST epoch], 16 seconds.\n",
      "\n",
      "-- train epoch 1/50, batch 266/266 (100.00%), loss = 506.47.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 1/50 \"f1-alpha-match-10\" train / dev / test | 56.50 / 57.03 / 55.28.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 2/50, batch 266/266 (100.00%), loss = 293.01.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 2/50 \"f1-alpha-match-10\" train / dev / test | 65.03 / 62.86 / 74.83.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 3/50, batch 266/266 (100.00%), loss = 285.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 3/50 \"f1-alpha-match-10\" train / dev / test | 69.40 / 65.18 / 67.61.\n",
      "## [BEST epoch], 101 seconds.\n",
      "\n",
      "-- train epoch 4/50, batch 266/266 (100.00%), loss = 256.61.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 4/50 \"f1-alpha-match-10\" train / dev / test | 70.53 / 65.92 / 81.06.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 5/50, batch 266/266 (100.00%), loss = 216.44.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 5/50 \"f1-alpha-match-10\" train / dev / test | 73.00 / 67.71 / 76.03.\n",
      "## [BEST epoch], 105 seconds.\n",
      "\n",
      "-- train epoch 6/50, batch 266/266 (100.00%), loss = 213.87.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 6/50 \"f1-alpha-match-10\" train / dev / test | 74.42 / 69.89 / 83.17.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 7/50, batch 266/266 (100.00%), loss = 178.25.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 7/50 \"f1-alpha-match-10\" train / dev / test | 79.90 / 73.00 / 82.31.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 8/50, batch 266/266 (100.00%), loss = 166.79.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 8/50 \"f1-alpha-match-10\" train / dev / test | 81.24 / 74.12 / 75.35.\n",
      "## [BEST epoch], 100 seconds.\n",
      "\n",
      "-- train epoch 9/50, batch 266/266 (100.00%), loss = 165.09.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 9/50 \"f1-alpha-match-10\" train / dev / test | 81.79 / 74.02 / 87.66.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=74.12), 102 seconds].\n",
      "\n",
      "-- train epoch 10/50, batch 266/266 (100.00%), loss = 163.07.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 10/50 \"f1-alpha-match-10\" train / dev / test | 83.59 / 75.25 / 87.07.\n",
      "## [BEST epoch], 95 seconds.\n",
      "\n",
      "-- train epoch 11/50, batch 266/266 (100.00%), loss = 149.60.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 11/50 \"f1-alpha-match-10\" train / dev / test | 85.12 / 77.45 / 92.16.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 12/50, batch 266/266 (100.00%), loss = 156.03.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 12/50 \"f1-alpha-match-10\" train / dev / test | 85.94 / 76.87 / 93.16.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=77.45), 99 seconds].\n",
      "\n",
      "-- train epoch 13/50, batch 266/266 (100.00%), loss = 120.16.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 13/50 \"f1-alpha-match-10\" train / dev / test | 86.34 / 77.91 / 95.48.\n",
      "## [BEST epoch], 95 seconds.\n",
      "\n",
      "-- train epoch 14/50, batch 266/266 (100.00%), loss = 123.61.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 14/50 \"f1-alpha-match-10\" train / dev / test | 87.54 / 77.82 / 89.63.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=77.91), 105 seconds].\n",
      "\n",
      "-- train epoch 15/50, batch 266/266 (100.00%), loss = 122.17.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 15/50 \"f1-alpha-match-10\" train / dev / test | 88.34 / 78.37 / 91.50.\n",
      "## [BEST epoch], 98 seconds.\n",
      "\n",
      "-- train epoch 16/50, batch 266/266 (100.00%), loss = 124.11.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 16/50 \"f1-alpha-match-10\" train / dev / test | 87.69 / 79.05 / 89.84.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 17/50, batch 266/266 (100.00%), loss = 110.95.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 17/50 \"f1-alpha-match-10\" train / dev / test | 89.31 / 79.25 / 88.74.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 18/50, batch 266/266 (100.00%), loss = 115.87.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 18/50 \"f1-alpha-match-10\" train / dev / test | 88.30 / 78.56 / 89.40.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=79.25), 96 seconds].\n",
      "\n",
      "-- train epoch 19/50, batch 266/266 (100.00%), loss = 112.29.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 19/50 \"f1-alpha-match-10\" train / dev / test | 90.22 / 79.26 / 88.37.\n",
      "## [BEST epoch], 100 seconds.\n",
      "\n",
      "-- train epoch 20/50, batch 266/266 (100.00%), loss = 113.93.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 20/50 \"f1-alpha-match-10\" train / dev / test | 89.82 / 80.26 / 89.93.\n",
      "## [BEST epoch], 99 seconds.\n",
      "\n",
      "-- train epoch 21/50, batch 266/266 (100.00%), loss = 104.21.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 21/50 \"f1-alpha-match-10\" train / dev / test | 90.65 / 80.07 / 88.29.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=80.26), 96 seconds].\n",
      "\n",
      "-- train epoch 22/50, batch 266/266 (100.00%), loss = 92.11.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 22/50 \"f1-alpha-match-10\" train / dev / test | 91.51 / 79.15 / 90.20.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=80.26), 100 seconds].\n",
      "\n",
      "-- train epoch 23/50, batch 266/266 (100.00%), loss = 100.87.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 23/50 \"f1-alpha-match-10\" train / dev / test | 91.63 / 79.16 / 95.45.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=80.26), 105 seconds].\n",
      "\n",
      "-- train epoch 24/50, batch 266/266 (100.00%), loss = 91.38.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 24/50 \"f1-alpha-match-10\" train / dev / test | 91.22 / 80.52 / 94.16.\n",
      "## [BEST epoch], 106 seconds.\n",
      "\n",
      "-- train epoch 25/50, batch 266/266 (100.00%), loss = 89.88.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 25/50 \"f1-alpha-match-10\" train / dev / test | 92.55 / 81.25 / 95.18.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 26/50, batch 266/266 (100.00%), loss = 89.55.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 26/50 \"f1-alpha-match-10\" train / dev / test | 92.84 / 81.63 / 97.11.\n",
      "## [BEST epoch], 102 seconds.\n",
      "\n",
      "-- train epoch 27/50, batch 266/266 (100.00%), loss = 86.33.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 27/50 \"f1-alpha-match-10\" train / dev / test | 92.99 / 82.06 / 96.13.\n",
      "## [BEST epoch], 104 seconds.\n",
      "\n",
      "-- train epoch 28/50, batch 266/266 (100.00%), loss = 83.85.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 28/50 \"f1-alpha-match-10\" train / dev / test | 93.67 / 81.28 / 95.18.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.06), 102 seconds].\n",
      "\n",
      "-- train epoch 29/50, batch 266/266 (100.00%), loss = 53.73.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 29/50 \"f1-alpha-match-10\" train / dev / test | 94.10 / 81.27 / 95.51.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.06), 104 seconds].\n",
      "\n",
      "-- train epoch 30/50, batch 266/266 (100.00%), loss = 84.95.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 30/50 \"f1-alpha-match-10\" train / dev / test | 93.85 / 82.20 / 92.16.\n",
      "## [BEST epoch], 103 seconds.\n",
      "\n",
      "-- train epoch 31/50, batch 266/266 (100.00%), loss = 64.91.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 31/50 \"f1-alpha-match-10\" train / dev / test | 94.19 / 82.18 / 94.16.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=82.20), 103 seconds].\n",
      "\n",
      "-- train epoch 32/50, batch 266/266 (100.00%), loss = 73.66.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 32/50 \"f1-alpha-match-10\" train / dev / test | 94.66 / 80.73 / 95.15.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=82.20), 98 seconds].\n",
      "\n",
      "-- train epoch 33/50, batch 266/266 (100.00%), loss = 54.31.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 33/50 \"f1-alpha-match-10\" train / dev / test | 94.82 / 81.30 / 95.48.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=82.20), 97 seconds].\n",
      "\n",
      "-- train epoch 34/50, batch 266/266 (100.00%), loss = 65.10.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 34/50 \"f1-alpha-match-10\" train / dev / test | 94.72 / 81.36 / 95.48.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=82.20), 97 seconds].\n",
      "\n",
      "-- train epoch 35/50, batch 266/266 (100.00%), loss = 69.23.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 35/50 \"f1-alpha-match-10\" train / dev / test | 94.61 / 83.35 / 94.81.\n",
      "## [BEST epoch], 98 seconds.\n",
      "\n",
      "-- train epoch 36/50, batch 266/266 (100.00%), loss = 63.74.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 36/50 \"f1-alpha-match-10\" train / dev / test | 94.90 / 81.79 / 96.13.\n",
      "## [no improvement micro-f1 on DEV during the last 1 epochs (best_f1_dev=83.35), 103 seconds].\n",
      "\n",
      "-- train epoch 37/50, batch 266/266 (100.00%), loss = 60.41.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 37/50 \"f1-alpha-match-10\" train / dev / test | 94.99 / 81.42 / 96.77.\n",
      "## [no improvement micro-f1 on DEV during the last 2 epochs (best_f1_dev=83.35), 98 seconds].\n",
      "\n",
      "-- train epoch 38/50, batch 266/266 (100.00%), loss = 69.72.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 38/50 \"f1-alpha-match-10\" train / dev / test | 95.17 / 82.28 / 97.44.\n",
      "## [no improvement micro-f1 on DEV during the last 3 epochs (best_f1_dev=83.35), 99 seconds].\n",
      "\n",
      "-- train epoch 39/50, batch 266/266 (100.00%), loss = 60.51.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 39/50 \"f1-alpha-match-10\" train / dev / test | 94.87 / 81.64 / 97.11.\n",
      "## [no improvement micro-f1 on DEV during the last 4 epochs (best_f1_dev=83.35), 105 seconds].\n",
      "\n",
      "-- train epoch 40/50, batch 266/266 (100.00%), loss = 54.05.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 40/50 \"f1-alpha-match-10\" train / dev / test | 95.41 / 81.16 / 95.51.\n",
      "## [no improvement micro-f1 on DEV during the last 5 epochs (best_f1_dev=83.35), 99 seconds].\n",
      "\n",
      "-- train epoch 41/50, batch 266/266 (100.00%), loss = 51.64.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 41/50 \"f1-alpha-match-10\" train / dev / test | 95.78 / 82.38 / 95.18.\n",
      "## [no improvement micro-f1 on DEV during the last 6 epochs (best_f1_dev=83.35), 102 seconds].\n",
      "\n",
      "-- train epoch 42/50, batch 266/266 (100.00%), loss = 49.02.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 42/50 \"f1-alpha-match-10\" train / dev / test | 95.71 / 82.13 / 95.15.\n",
      "## [no improvement micro-f1 on DEV during the last 7 epochs (best_f1_dev=83.35), 100 seconds].\n",
      "\n",
      "-- train epoch 43/50, batch 266/266 (100.00%), loss = 67.12.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 43/50 \"f1-alpha-match-10\" train / dev / test | 95.82 / 82.05 / 94.16.\n",
      "## [no improvement micro-f1 on DEV during the last 8 epochs (best_f1_dev=83.35), 100 seconds].\n",
      "\n",
      "-- train epoch 44/50, batch 266/266 (100.00%), loss = 48.82.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 44/50 \"f1-alpha-match-10\" train / dev / test | 95.57 / 81.13 / 94.19.\n",
      "## [no improvement micro-f1 on DEV during the last 9 epochs (best_f1_dev=83.35), 98 seconds].\n",
      "\n",
      "-- train epoch 45/50, batch 266/266 (100.00%), loss = 58.58.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 45/50 \"f1-alpha-match-10\" train / dev / test | 95.63 / 80.84 / 94.53.\n",
      "## [no improvement micro-f1 on DEV during the last 10 epochs (best_f1_dev=83.35), 97 seconds].\n",
      "\n",
      "-- train epoch 46/50, batch 266/266 (100.00%), loss = 58.45.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 46/50 \"f1-alpha-match-10\" train / dev / test | 96.01 / 82.27 / 94.87.\n",
      "## [no improvement micro-f1 on DEV during the last 11 epochs (best_f1_dev=83.35), 97 seconds].\n",
      "\n",
      "-- train epoch 47/50, batch 266/266 (100.00%), loss = 45.80.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 47/50 \"f1-alpha-match-10\" train / dev / test | 95.88 / 82.92 / 95.18.\n",
      "## [no improvement micro-f1 on DEV during the last 12 epochs (best_f1_dev=83.35), 101 seconds].\n",
      "\n",
      "-- train epoch 48/50, batch 266/266 (100.00%), loss = 56.86.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 48/50 \"f1-alpha-match-10\" train / dev / test | 96.02 / 81.93 / 94.19.\n",
      "## [no improvement micro-f1 on DEV during the last 13 epochs (best_f1_dev=83.35), 102 seconds].\n",
      "\n",
      "-- train epoch 49/50, batch 266/266 (100.00%), loss = 65.81.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 49/50 \"f1-alpha-match-10\" train / dev / test | 96.06 / 82.31 / 93.89.\n",
      "## [no improvement micro-f1 on DEV during the last 14 epochs (best_f1_dev=83.35), 103 seconds].\n",
      "\n",
      "-- train epoch 50/50, batch 266/266 (100.00%), loss = 49.83.\n",
      "\n",
      "++ predicting, batch 26/26 (97.00%).\n",
      "\n",
      "++ predicting, batch 3/3 (67.00%).\n",
      "\n",
      "++ predicting, batch 1/1 (0.00%).\n",
      "== eval epoch 50/50 \"f1-alpha-match-10\" train / dev / test | 96.43 / 81.62 / 94.87.\n",
      "## [no improvement micro-f1 on DEV during the last 15 epochs (best_f1_dev=83.35), 100 seconds].\n",
      "\n",
      "Evaluation\n",
      "\n",
      "batch_size=10\n",
      "char_cnn_filter_num=30\n",
      "char_embeddings_dim=25\n",
      "char_window_size=3\n",
      "check_for_lowercase=True\n",
      "clip_grad=5\n",
      "cross_fold_id=-1\n",
      "cross_folds_num=-1\n",
      "data_io='connl-ner-2003'\n",
      "dataset_sort=False\n",
      "dev='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv'\n",
      "dropout_ratio=0.5\n",
      "elmo_options='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
      "elmo_weights='/home/vika/NER_RNN/targer/embeddings/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
      "emb_delimiter=' '\n",
      "emb_dim=100\n",
      "emb_fn='embeddings/glove.6B.100d.txt'\n",
      "emb_load_all=False\n",
      "epoch_num=50\n",
      "evaluator='f1-alpha-match-10'\n",
      "freeze_char_embeddings=False\n",
      "freeze_word_embeddings=False\n",
      "gpu=1\n",
      "isElmo=True\n",
      "load=None\n",
      "lr=0.001\n",
      "lr_decay=0.05\n",
      "min_epoch_num=50\n",
      "model='BiRNNCNNCRF'\n",
      "momentum=0.9\n",
      "opt='adam'\n",
      "patience=20\n",
      "report_fn='2019_09_05_18-22_25_report.txt'\n",
      "rnn_hidden_dim=200\n",
      "rnn_type='LSTM'\n",
      "save='new_tagger1.hdf5'\n",
      "save_best=True\n",
      "seed_num=42\n",
      "test='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv'\n",
      "train='/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv'\n",
      "verbose=True\n",
      "word_len=20\n",
      "word_seq_indexer=None\n",
      "\n",
      "         epoch  |     train loss | f1-alpha-match-10-train | f1-alpha-match-10-dev | f1-alpha-match-10-test \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "              0 |           0.00 |           2.86 |           3.55 |           8.28 \n",
      "              1 |         506.47 |          56.50 |          57.03 |          55.28 \n",
      "              2 |         293.01 |          65.03 |          62.86 |          74.83 \n",
      "              3 |         285.58 |          69.40 |          65.18 |          67.61 \n",
      "              4 |         256.61 |          70.53 |          65.92 |          81.06 \n",
      "              5 |         216.44 |          73.00 |          67.71 |          76.03 \n",
      "              6 |         213.87 |          74.42 |          69.89 |          83.17 \n",
      "              7 |         178.25 |          79.90 |          73.00 |          82.31 \n",
      "              8 |         166.79 |          81.24 |          74.12 |          75.35 \n",
      "              9 |         165.09 |          81.79 |          74.02 |          87.66 \n",
      "             10 |         163.07 |          83.59 |          75.25 |          87.07 \n",
      "             11 |         149.60 |          85.12 |          77.45 |          92.16 \n",
      "             12 |         156.03 |          85.94 |          76.87 |          93.16 \n",
      "             13 |         120.16 |          86.34 |          77.91 |          95.48 \n",
      "             14 |         123.61 |          87.54 |          77.82 |          89.63 \n",
      "             15 |         122.17 |          88.34 |          78.37 |          91.50 \n",
      "             16 |         124.11 |          87.69 |          79.05 |          89.84 \n",
      "             17 |         110.95 |          89.31 |          79.25 |          88.74 \n",
      "             18 |         115.87 |          88.30 |          78.56 |          89.40 \n",
      "             19 |         112.29 |          90.22 |          79.26 |          88.37 \n",
      "             20 |         113.93 |          89.82 |          80.26 |          89.93 \n",
      "             21 |         104.21 |          90.65 |          80.07 |          88.29 \n",
      "             22 |          92.11 |          91.51 |          79.15 |          90.20 \n",
      "             23 |         100.87 |          91.63 |          79.16 |          95.45 \n",
      "             24 |          91.38 |          91.22 |          80.52 |          94.16 \n",
      "             25 |          89.88 |          92.55 |          81.25 |          95.18 \n",
      "             26 |          89.55 |          92.84 |          81.63 |          97.11 \n",
      "             27 |          86.33 |          92.99 |          82.06 |          96.13 \n",
      "             28 |          83.85 |          93.67 |          81.28 |          95.18 \n",
      "             29 |          53.73 |          94.10 |          81.27 |          95.51 \n",
      "             30 |          84.95 |          93.85 |          82.20 |          92.16 \n",
      "             31 |          64.91 |          94.19 |          82.18 |          94.16 \n",
      "             32 |          73.66 |          94.66 |          80.73 |          95.15 \n",
      "             33 |          54.31 |          94.82 |          81.30 |          95.48 \n",
      "             34 |          65.10 |          94.72 |          81.36 |          95.48 \n",
      "             35 |          69.23 |          94.61 |          83.35 |          94.81 \n",
      "             36 |          63.74 |          94.90 |          81.79 |          96.13 \n",
      "             37 |          60.41 |          94.99 |          81.42 |          96.77 \n",
      "             38 |          69.72 |          95.17 |          82.28 |          97.44 \n",
      "             39 |          60.51 |          94.87 |          81.64 |          97.11 \n",
      "             40 |          54.05 |          95.41 |          81.16 |          95.51 \n",
      "             41 |          51.64 |          95.78 |          82.38 |          95.18 \n",
      "             42 |          49.02 |          95.71 |          82.13 |          95.15 \n",
      "             43 |          67.12 |          95.82 |          82.05 |          94.16 \n",
      "             44 |          48.82 |          95.57 |          81.13 |          94.19 \n",
      "             45 |          58.58 |          95.63 |          80.84 |          94.53 \n",
      "             46 |          58.45 |          96.01 |          82.27 |          94.87 \n",
      "             47 |          45.80 |          95.88 |          82.92 |          95.18 \n",
      "             48 |          56.86 |          96.02 |          81.93 |          94.19 \n",
      "             49 |          65.81 |          96.06 |          82.31 |          93.89 \n",
      "             50 |          49.83 |          96.43 |          81.62 |          94.87 \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Final eval on test, \"save best\", best epoch on dev 35, f1-alpha-match-10, test = 94.81)\n",
      "--------------------------------------------------------------------------------------------------------------*** f1 alpha match, alpha = 1.0\n",
      "*** f1 = 94.81, precision = 96.69, recall = 92.99\n",
      "*** TP = 146, FP = 5, FN = 11\n",
      "Input arguments:\n",
      "python3 main.py --train /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv --dev /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test /home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv --epoch-num 50 --isElmo True --save new_tagger1.hdf5\n",
      "\n",
      "94.8052\n"
     ]
    }
   ],
   "source": [
    "! python3 main.py --train \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_train_new.csv\" --dev \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_dev.csv\" --data-io connl-ner-2003 --evaluator f1-alpha-match-10 --opt adam --lr 0.001 --save-best yes --patience 20 --rnn-hidden-dim 200 --gpu 1 --test \"/home/vika/NER_RNN/targer/data/NER/Asqua_CAM_aspects/CAM_qw_new.csv\" --epoch-num 50 --isElmo True --save \"new_tagger1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vika/NER_RNN/targer\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
